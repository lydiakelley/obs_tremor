{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09c91f7-a06d-42da-95cc-fe7fe003ed6b",
   "metadata": {},
   "source": [
    "## Classify emergent detections from STA/LTA on the basis of waveform characteristics\n",
    "- runs in parallel over the list of detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8da0ee-4b71-43a2-9e31-ff153937af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.clients.fdsn.client import Client \n",
    "import obspy\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "import geopy.distance\n",
    "import random\n",
    "client = Client('IRIS')\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f11cf-3c7f-4951-808f-d0925a92eab7",
   "metadata": {},
   "source": [
    "## Pull in emergent detections from STA/LTA triggering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb46d47a-f951-4ff0-bf68-addcd7fa013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'OO'\n",
    "station = 'HYS14'\n",
    "channel = 'HHN'\n",
    "samp_rate = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f14fac5-9736-4fef-a1ca-516064f13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all:\n",
    "file_name='results/HYSB1_HHN_3-10Hz_triggering.pickle'\n",
    "with open(file_name,'rb') as handle:\n",
    "    detections = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b9c799-6e3a-453b-95b1-70a12e01b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the detections based on time, if desired!\n",
    "t1 = obspy.UTCDateTime(2017,9,1)\n",
    "t2 = obspy.UTCDateTime(2017,9,8)\n",
    "\n",
    "t_keep = [i for i,e in enumerate(detections) if (e[0]>t1) & (e[0]<t2)]\n",
    "detections = [detections[i] for i in t_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5c18a-6c7b-4e3f-b539-e0c044a23a56",
   "metadata": {},
   "source": [
    "## Define classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8671ed3c-d40b-4788-b557-dce608f29630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_peaks_welch(trace,sampling_rate,nperseg_multiple,microseism_cutoff=True):\n",
    "    \"\"\"\n",
    "    Estimate power spectra of a trace using Welch's method\n",
    "    Pick peaks within the spectra!\n",
    "    \n",
    "    INPUTS:\n",
    "    trace = obspy object, waveform\n",
    "    sampling_rate = sampling rate of trace\n",
    "    nperseg_multiple = length of each segment used to construct the Welch spectrum\n",
    "    microseism_cutoff = Bool, whether or not to cut off the lower end of the spectrum to avoid the microseism\n",
    "    \n",
    "    OUTPUTS:\n",
    "    f = frequencies of the spectra\n",
    "    Pxx_den = associated power at each frequency, in decibels\n",
    "    peak_ind = index of peaks within the spectra (f and Pxx_den), if found\n",
    "    peaks = picked peak object from scipy\n",
    "    median_power = median power of spectra from 20-80 Hz in decibels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fs = sampling_rate\n",
    "    x = trace.data\n",
    "    nperseg = fs * nperseg_multiple\n",
    "    \n",
    "    f,Pxx_den = scipy.signal.welch(x,fs,nperseg=nperseg)\n",
    "    if microseism_cutoff is True:\n",
    "        f = f[4:]\n",
    "        Pxx_den = Pxx_den[4:]\n",
    "        \n",
    "    Pxx_den = [10*np.log10(d) for d in Pxx_den]\n",
    "    median_power = np.median(Pxx_den[20:80])\n",
    "    \n",
    "    peaks = scipy.signal.find_peaks(Pxx_den,threshold =median_power*5,prominence=10) \n",
    "    peak_ind = peaks[0]\n",
    "    \n",
    "    return(f,Pxx_den,peak_ind,peaks,median_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16351ccc-63a5-4c47-bef1-afdabd738f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_gaussian(filtered_data,samp_rate,gaussian_width=5):\n",
    "    \"\"\"\n",
    "    Smooth waveform using a gaussian window\n",
    "    \n",
    "    INPUTS\n",
    "    filtered_data = filtered numpy array of seismic data (from an obspy trace)\n",
    "    samp_rate = sampling rate of data\n",
    "    gaussian width = width of Gaussian window in seconds\n",
    "    \n",
    "    OUTPUTS\n",
    "    smoothed_window = smoothed numpy array of seismic data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Square data\n",
    "    data = filtered_data**2\n",
    "    \n",
    "    gaussian_radius = int((gaussian_width * samp_rate)/2)\n",
    "    smoothed_window=scipy.ndimage.gaussian_filter1d(data,sigma=gaussian_radius/4,radius=gaussian_radius)\n",
    "    \n",
    "    return smoothed_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ca28da-a4a8-4081-a280-db6d3ef8b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ship_noise_classifier(trace,sampling_rate):\n",
    "    \"\"\"\n",
    "    Check whether detection likely includes ship noise in the form of a spectral peak\n",
    "    \n",
    "    INPUTS\n",
    "    trace = obspy trace object\n",
    "    sampling_rate = sample rate of trace\n",
    "    \n",
    "    OUTPUTS\n",
    "    ship_classifier = number of peaks in the spectra. If any exist, ship noise is likely!\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Pick peaks on the smoothed spectrum of the trace (nperseg multiple = 1)\n",
    "    f,Pxx_den,peak_ind,peak_details,median_power = pick_peaks_welch(trace,sampling_rate,1,microseism_cutoff=True)\n",
    "    \n",
    "    if len(peak_ind)==0:\n",
    "        ship_classifier = 0\n",
    "    else:\n",
    "        ship_classifier = len(peak_ind)\n",
    "\n",
    "    \n",
    "    return ship_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e1f3f-2de3-4a2e-a940-3c652d4dc28b",
   "metadata": {},
   "source": [
    "1. Calculate whether the detection likely includes ship noise (whether there are peaks in the Welch spectra)\n",
    "2. Perform 15 s Gaussian smoothing on filtered (4-15 Hz) waveform, calculate number of peaks with prominence > 0.1\n",
    "- 1 peak indicates T-phase, > 1 peak is consistent with tremor\n",
    "3. Calculate frequency ratio (ratio between power in 5-10 and 10-15 Hz) with 30 s padding on either side\n",
    "- Frequency ratio > 100 is consistent with tectonic tremor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17d9622-f5c3-48ec-896d-d8db0e481620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_detection(t,network,station,channel,samp_rate,filepath):\n",
    "    \"\"\"\n",
    "    INPUTS \n",
    "    t = tuple of UTCDatetime, with on and off trigger time of detection\n",
    "    network = string\n",
    "    station = string\n",
    "    channel = string\n",
    "    samp_rate = sampling rate of channel\n",
    "    filepath = directory to save classification information to\n",
    "    \n",
    "    \n",
    "    OUTPUTS\n",
    "    Writes to file!\n",
    "    t = on and off times of detection\n",
    "    num_waveform_peaks = number of peaks with prominence > 0 in gaussian smoothed 4-15 Hz filtered waveform; more than 1 indicates a T-phase\n",
    "    ship_classifier = number of peaks in the Welch spectra, existence of peaks indicates ship noise\n",
    "    freq_ratio_welch = ratio between normalized decibels of Welch spectrum for 5-10 and 10-15 Hz. Values > 100 indicate tectonic tremor\n",
    "    max_amplitude = maximum amplitude of filtered waveform\n",
    "    \"\"\"\n",
    "    file_name = filepath +  station + '_' + str(t[0]).split('.')[0] + '.pickle'\n",
    "    if os.path.isfile(file_name)==True:\n",
    "        return\n",
    "    \n",
    "    # try:\n",
    "    pad = 0\n",
    "    t1 = t[0]-pad\n",
    "    t2 = t[1]+pad\n",
    "\n",
    "    # Check whether there are peaks in the Welch spectra\n",
    "    # If ship_classifier > 0, indicates presence of ship noise\n",
    "    st1 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "    st1.resample(samp_rate).merge(fill_value='interpolate')\n",
    "    st1[0].data = st1[0].data / st1[0].stats.response.instrument_sensitivity.value # Convert to m/s\n",
    "    st1.trim(starttime=t1,endtime=t2)\n",
    "    ship_classifier = ship_noise_classifier(st1[0],samp_rate)\n",
    "\n",
    "    # Get number of peaks in Gaussian-smoothed waveform\n",
    "    # If number of peaks = 1, indicates T-phase\n",
    "    st1 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "    st1.resample(samp_rate).merge(fill_value='interpolate')\n",
    "    st1.filter('bandpass',freqmin=3,freqmax=10)\n",
    "    st1.remove_response()\n",
    "    st1.trim(starttime=t1,endtime=t2)\n",
    "    max_amplitude = np.max(np.abs(st1[0].data))\n",
    "    smoothed_window = apply_gaussian(st1[0].data,samp_rate,gaussian_width=15)\n",
    "    window_max = np.max(smoothed_window) # normalize window by its maximum\n",
    "    smoothed_window = [i/window_max for i in smoothed_window]\n",
    "    peaks = scipy.signal.find_peaks(smoothed_window,prominence=.1)\n",
    "    num_waveform_peaks=len(peaks[0])\n",
    "\n",
    "    # Calculate frequency ratio with 30 s padding on either side - using Welch\n",
    "    pad = 30\n",
    "    t1 = t[0]-pad\n",
    "    t2 = t[1]+pad\n",
    "    st2 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "    st2.resample(samp_rate).merge(fill_value='interpolate')\n",
    "    st2[0].data = st2[0].data / st2[0].stats.response.instrument_sensitivity.value # Convert to m/s\n",
    "    st2.trim(starttime=t1,endtime=t2)\n",
    "    f,Pxx_den,peak_ind,peak_details,median_power = pick_peaks_welch(st2[0],samp_rate,5,microseism_cutoff=False)\n",
    "    normalized_power = Pxx_den\n",
    "    freq_ratio = 10**(np.median(normalized_power[25:50])/10)/10**(np.median(normalized_power[50:75])/10)\n",
    "    freq_ratio_welch=freq_ratio\n",
    "\n",
    "    # Write results to file\n",
    "    file_name = filepath +  station + '_' + str(t[0]).split('.')[0] + '.pickle'\n",
    "    with open(file_name, 'wb') as handle:\n",
    "            pickle.dump([t,station,num_waveform_peaks,ship_classifier,freq_ratio_welch,max_amplitude],handle)\n",
    "    '''\n",
    "    except:\n",
    "        didntwork = 1\n",
    "    \n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906abaec-6c6f-4a54-bb14-ea6df354a935",
   "metadata": {},
   "source": [
    "## Loop in parallel\n",
    "Note: simply overwrites files if they already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5dec3e8-83f1-4c4b-8743-818b380be074",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'classifications/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64979d0-f141-4cd5-963b-a347cf75f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def loop_detections(t,network,station,channel,samp_rate,filepath):\n",
    "    return classify_detection(t,network,station,channel,samp_rate,filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72bda223-9b71-4029-9f7c-2c54f22df57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_results = [loop_detections(t,network,station,channel,samp_rate,filepath) for t in detections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503e930b-9bfa-4694-9adf-a4e03cc007c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################                        ] | 42% Completed | 25.78 ss\n"
     ]
    },
    {
     "ename": "FDSNNoDataException",
     "evalue": "No data available for request.\nHTTP Status code: 204\nDetailed response of server:\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFDSNNoDataException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlazy_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/dask/base.py:665\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 665\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mloop_detections\u001b[0;34m(t, network, station, channel, samp_rate, filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@dask\u001b[39m\u001b[38;5;241m.\u001b[39mdelayed\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_detections\u001b[39m(t,network,station,channel,samp_rate,filepath):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamp_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36mclassify_detection\u001b[0;34m(t, network, station, channel, samp_rate, filepath)\u001b[0m\n\u001b[1;32m     27\u001b[0m t2 \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mpad\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check whether there are peaks in the Welch spectra\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If ship_classifier > 0, indicates presence of ship noise\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m st1 \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_waveforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mattach_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[1;32m     32\u001b[0m st1\u001b[38;5;241m.\u001b[39mresample(samp_rate)\u001b[38;5;241m.\u001b[39mmerge(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m st1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m st1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m/\u001b[39m st1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39minstrument_sensitivity\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;66;03m# Convert to m/s\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/obspy/clients/fdsn/client.py:872\u001b[0m, in \u001b[0;36mClient.get_waveforms\u001b[0;34m(self, network, station, location, channel, starttime, endtime, quality, minimumlength, longestonly, filename, attach_response, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_url_from_parameters(\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_PARAMETERS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# Gzip not worth it for MiniSEED and most likely disabled for this\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# route in any case.\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m data_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m data_stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/obspy/clients/fdsn/client.py:1486\u001b[0m, in \u001b[0;36mClient._download\u001b[0;34m(self, url, return_string, data, use_gzip, content_type)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m content_type\n\u001b[1;32m   1482\u001b[0m code, data \u001b[38;5;241m=\u001b[39m download_url(\n\u001b[1;32m   1483\u001b[0m     url, opener\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_opener, headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1484\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug, return_string\u001b[38;5;241m=\u001b[39mreturn_string, data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1485\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, use_gzip\u001b[38;5;241m=\u001b[39muse_gzip)\n\u001b[0;32m-> 1486\u001b[0m \u001b[43mraise_on_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo2/lib/python3.10/site-packages/obspy/clients/fdsn/client.py:1813\u001b[0m, in \u001b[0;36mraise_on_error\u001b[0;34m(code, data)\u001b[0m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;66;03m# No data.\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m204\u001b[39m:\n\u001b[0;32m-> 1813\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FDSNNoDataException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data available for request.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1814\u001b[0m                               server_info)\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m   1816\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad request. If you think your request was valid \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1817\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease contact the developers.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFDSNNoDataException\u001b[0m: No data available for request.\nHTTP Status code: 204\nDetailed response of server:\n\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    results = dask.compute(lazy_results,num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8c1131-2276-4c46-97a6-289a32fdc550",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'triggers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mlen\u001b[39m(detections)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtriggers\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'triggers' is not defined"
     ]
    }
   ],
   "source": [
    "len(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8934a-c800-4673-8424-a2d7068d41ba",
   "metadata": {},
   "source": [
    "## Pull in all saved files of classifications and save to one pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "178c3cbd-b7bf-4498-b6cd-73e680d2123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(filepath+station+'*')\n",
    "\n",
    "classifications = []\n",
    "for f in files:\n",
    "    with open(f,'rb') as handle:\n",
    "        classi = pickle.load(handle)\n",
    "        classifications.append(classi)\n",
    "        \n",
    "# Sort!\n",
    "times = [c[0][0] for c in classifications]\n",
    "sort_ind = np.argsort(times)\n",
    "classifications = [classifications[i] for i in sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c471a8-35ef-4808-9d77-2ebf3910b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write all to pickle\n",
    "file_name = 'EBS3_EH1_3-10Hz_classifications_new.pickle'\n",
    "pickle.dump(classifications,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21800738-f161-40e6-882b-8de7af710136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282c8e1-b3f0-4e29-9dd2-008ce94d7aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo 3.10 (SHARED)",
   "language": "python",
   "name": "seismo-py310-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
