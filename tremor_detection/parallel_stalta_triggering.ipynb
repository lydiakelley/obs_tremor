{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e63884e-9467-4b88-881b-5c734970c017",
   "metadata": {},
   "source": [
    "## Make detections on individual emergent signals on continuous data in parallel using STA/LTA triggering\n",
    "- In parallel over days using dask\n",
    "- Runs on one channel on one station at a time\n",
    "- NOTE THAT THE 3-10 HZ FILTER IS HARD CODED IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea7d2fd-e812-404a-b93d-e80fa58f9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from obspy.clients.fdsn.client import Client\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "matplotlib.rcParams['font.family']=['Arial']\n",
    "client = Client('IRIS')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf12c03-4e2a-4593-ae76-e54abced0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.trigger import classic_sta_lta\n",
    "from obspy.signal.trigger import trigger_onset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417592c-6cc8-4c92-ae9e-0f10026adbce",
   "metadata": {},
   "source": [
    "### STA/LTA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1ed9ec-5fa8-4071-9b54-352c2fce9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling rate and step we want to chunk\n",
    "sr = 200\n",
    "step = 10 # seconds\n",
    "\n",
    "# Define sta and lta window lengths\n",
    "# Below chosen to optimize emergent signal detection!\n",
    "sta_win = 10 # seconds, short term window\n",
    "lta_win = 1000 # seconds, long term window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7df55-2f97-4817-8106-09a65226dec3",
   "metadata": {},
   "source": [
    "### Time endpoints and station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3c14ba-30f1-4918-a992-980a5cb50845",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = obspy.UTCDateTime(\"2018-07-01T00:00:00.000\")\n",
    "t2 = obspy.UTCDateTime(\"2019-07-01T00:00:00.000\")\n",
    "\n",
    "network = 'OO'\n",
    "station = 'HYS14'\n",
    "channel = 'HHN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab450c-6cab-467b-b454-11c6373526ab",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d349e1f9-4111-4267-9a51-b32358e4e197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trigger(t1,data_time_length,network,station,channel,sr,step,sta_win,lta_win):\n",
    "    \"\"\"\n",
    "    t1 = start of time period to process, UTCDateTime\n",
    "    data_time_length = overall length of time period, in seconds\n",
    "    network = network code of desired station, string\n",
    "    station = station code, string\n",
    "    channel = channel code, string\n",
    "    sr = sampling rate of desired channel\n",
    "    step = duration of length of time to step through data with (speeds up processing), seconds\n",
    "    sta_win = duration of short-term window, seconds\n",
    "    lta_win = duration of long-term window, seconds\n",
    "    \n",
    "    Outputs:\n",
    "    ontimes = list of on-times of all detection windows\n",
    "    offtimes = list of off-times of all detection windows\n",
    "    \"\"\"\n",
    "    \n",
    "    t2 = t1 + data_time_length + 1000 # to account for signals at end\n",
    "    t1 = t1 - 1000 # to account for signals at beginning\n",
    "    \n",
    "    \n",
    "    # Pull in data\n",
    "    try:\n",
    "        st1 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5);\n",
    "        st1.resample(sr).merge(fill_value=0)\n",
    "        st1.taper(0.05,max_length=5)\n",
    "        st1.filter('bandpass',freqmin=3,freqmax=10)\n",
    "        st1.trim(starttime=t1,endtime=t2)\n",
    "        \n",
    "        # Check to make sure there is data for the whole time period of t1 + data_time_length\n",
    "        # If not, adjust some values to reflect that\n",
    "        t1,data_time_length = check_data(st1,t1,sr,step,data_time_length)\n",
    "\n",
    "        # Run STA/LTA triggering\n",
    "        data = np.abs(st1[0].data)\n",
    "        stalta,times = calc_stalta(data,sr,step,data_time_length,sta_win,lta_win)\n",
    "\n",
    "        # Get triggers and the seconds they correspond to\n",
    "        triggers = trigger_onset(stalta,2,1)\n",
    "        ons = [times[tr[0]] for tr in triggers]\n",
    "        offs = [times[tr[1]] for tr in triggers]\n",
    "\n",
    "\n",
    "        # Get start and stop times of windows\n",
    "        ontimes = [t1+o for o in ons]\n",
    "        offtimes = [t1+o for o in offs]\n",
    "\n",
    "        return(ontimes,offtimes)\n",
    "\n",
    "    except:\n",
    "        print(['No data for ',str(t1)])\n",
    "        return([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc86da2d-0674-4c1f-beb8-b69cdf9599eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_data(stream,t1,sr,step,data_time_length):\n",
    "    \n",
    "    data = stream[0].data\n",
    "    data_sample_length = sr * data_time_length\n",
    "\n",
    "    \n",
    "    # Catch for if data stream is less than specified\n",
    "    if len(data) < data_sample_length:\n",
    "        data_sample_length = int(len(data) - (len(data)%(sr*step)))\n",
    "        data_time_length = int(data_sample_length / sr)\n",
    "        \n",
    "    # Catch for if start time is not as specified\n",
    "    if stream[0].stats.starttime != t1:\n",
    "        t1 = stream[0].stats.starttime\n",
    "    \n",
    "    return(t1,data_time_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a1f017-76a1-494d-9fb8-4197fcfb4635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stalta(data,sr,step,data_time_length,sta_win,lta_win):\n",
    "    \n",
    "    # Matricize the data as step s chunks\n",
    "    data_sample_length = sr * data_time_length\n",
    "    \n",
    "    \n",
    "    chunked = np.reshape(data[0:data_sample_length],[int(data_sample_length/(sr*step)),int(sr*step)])\n",
    "    chunked_medians = [np.median(chunked[i,:]) for i in range(np.shape(chunked)[0])]\n",
    "    chunked_times = np.linspace(0,data_time_length,len(chunked_medians))\n",
    "    \n",
    "    # Step through and calculate sta & lta every step s\n",
    "    sta = []\n",
    "    lta = []\n",
    "    for i,vec in enumerate(chunked_medians):\n",
    "\n",
    "        # STA is median of the next window\n",
    "        nwin = int(sta_win / step)\n",
    "        sta.append(np.median(chunked_medians[i:i+nwin]))\n",
    "\n",
    "\n",
    "        # LTA is median of the past window\n",
    "        nwin = int(lta_win / step)\n",
    "        lta.append(np.median(chunked_medians[i-nwin:i]))\n",
    "    \n",
    "    stalta = np.array(sta)/np.array(lta)\n",
    "    \n",
    "    return(stalta,chunked_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe2f95-e86a-4904-805c-ed039c3c80a1",
   "metadata": {},
   "source": [
    "### Bin data by days and process in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea210d7-ed28-41e0-b0c1-401b02879a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = pd.date_range(start=t1.datetime, end=t2.datetime, freq='d')\n",
    "data_time_length = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce75159-3a58-4e76-aaa5-898fb2758a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def loop_days(t1,data_time_length,network,station,channel,sr,step,sta_win,lta_win):\n",
    "    t1 = obspy.UTCDateTime(t1)\n",
    "    return trigger(t1,data_time_length,network,station,channel,sr,step,sta_win,lta_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c34143-36d9-4ca6-98ad-22ca31f3549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_results = [loop_days(t,data_time_length,network,station,channel,sr,step,sta_win,lta_win) for t in time_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503a7ebc-60c9-4955-bea2-2047ea304d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 22.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoekrauss/anaconda3/envs/alaska-ml/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/zoekrauss/anaconda3/envs/alaska-ml/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 22.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/tk8jpcf12gdbjj0htp_vqbtc0000gn/T/ipykernel_65160/1058069781.py:25: RuntimeWarning: overflow encountered in divide\n",
      "  stalta = np.array(sta)/np.array(lta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####                                    ] | 11% Completed |  2min 45.4s['No data for ', '2019-06-12T23:43:20.000000Z']\n",
      "[#####                                   ] | 13% Completed |  2min 57.5s['No data for ', '2019-06-15T23:43:20.000000Z']\n",
      "[######                                  ] | 15% Completed |  3min 32.6s['No data for ', '2019-05-26T23:43:20.000000Z']\n",
      "[#######                                 ] | 18% Completed |  4min  8.0s['No data for ', '2019-06-20T23:43:20.000000Z']\n",
      "[###########                             ] | 29% Completed |  6min 51.9s['No data for ', '2019-06-16T23:43:20.000000Z']\n",
      "[############                            ] | 30% Completed |  7min  9.6s['No data for ', '2018-12-18T23:43:20.000000Z']\n",
      "[############                            ] | 31% Completed |  7min 30.3s['No data for ', '2019-06-14T23:43:20.000000Z']\n",
      "[##############                          ] | 35% Completed |  8min 13.6s['No data for ', '2019-06-17T23:43:20.000000Z']\n",
      "[##############                          ] | 35% Completed |  8min 18.0s['No data for ', '2019-06-22T23:43:20.000000Z']\n",
      "[##############                          ] | 36% Completed |  8min 18.4s['No data for ', '2018-08-22T23:43:20.000000Z']\n",
      "[################                        ] | 40% Completed |  9min 18.7s['No data for ', '2018-12-17T23:43:20.000000Z']\n",
      "[###################                     ] | 49% Completed | 11min  2.1s['No data for ', '2019-06-13T23:43:20.000000Z']\n",
      "[########################                ] | 61% Completed | 13min 46.3s['No data for ', '2018-09-29T23:43:20.000000Z']\n",
      "[##########################              ] | 65% Completed | 14min 32.7s['No data for ', '2019-06-24T23:43:20.000000Z']\n",
      "[############################            ] | 71% Completed | 15min 49.9s['No data for ', '2018-08-28T23:43:20.000000Z']\n",
      "[############################            ] | 71% Completed | 15min 50.2s['No data for ', '2018-09-28T23:43:20.000000Z']\n",
      "[#############################           ] | 73% Completed | 16min 17.6s['No data for ', '2019-06-21T23:43:20.000000Z']\n",
      "[#############################           ] | 74% Completed | 16min 18.4s['No data for ', '2019-06-23T23:43:20.000000Z']\n",
      "[##############################          ] | 76% Completed | 16min 54.9s['No data for ', '2019-06-11T23:43:20.000000Z']\n",
      "[##################################      ] | 85% Completed | 19min  3.4s['No data for ', '2018-12-19T23:43:20.000000Z']\n",
      "[##################################      ] | 87% Completed | 19min 32.8s['No data for ', '2019-06-25T23:43:20.000000Z']\n",
      "[###################################     ] | 87% Completed | 19min 33.9s['No data for ', '2019-06-18T23:43:20.000000Z']\n",
      "[####################################    ] | 91% Completed | 20min 31.5s['No data for ', '2019-06-19T23:43:20.000000Z']\n",
      "[######################################  ] | 96% Completed | 22min  1.2s['No data for ', '2018-09-30T23:43:20.000000Z']\n",
      "[########################################] | 100% Completed | 22min 47.9s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    results = dask.compute(lazy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62beab9d-2f4f-416f-a12f-3d197b31bcdb",
   "metadata": {},
   "source": [
    "### Concat results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab2d5dc-71af-4454-8725-7f636b039de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='emergent_detections/'\n",
    "pickle_name='HYS14_2018_2019_HHN.pickle'\n",
    "ons = []\n",
    "offs = []\n",
    "for ap in results[0]:\n",
    "    if len(ap) > 0:\n",
    "        ons.extend(ap[0])\n",
    "        offs.extend(ap[1])\n",
    "sort_ind = np.argsort(ons)\n",
    "ons = [ons[i] for i in sort_ind]\n",
    "offs = [offs[i] for i in sort_ind]\n",
    "triggers = [[ons[i],offs[i]] for i in range(len(ons))]\n",
    "\n",
    "\n",
    "# Toss any with durations less than 30 s\n",
    "durations = [t[1]-t[0] for t in triggers]\n",
    "dur_keep = [i for i,e in enumerate(durations) if e >= 30]\n",
    "triggers = [triggers[i] for i in dur_keep]\n",
    "\n",
    "\n",
    "pickle.dump(triggers,open(pickle_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7d8f16-1a18-48d2-808c-cf9fbb091942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12348"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ab8d6-e30d-4d2b-a4c7-a05f66251865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alaska-ml",
   "language": "python",
   "name": "alaska-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
